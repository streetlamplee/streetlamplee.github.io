---
layout: post
title: DL 성능 고도화 방법 I
date: 2023-12-20 16:20 +0900
last_modified_at: 2023-12-20 17:13:00 +0900
tags: [DeepLearning]
toc:  true
---

# 성능 고도화 방법 I

## 1. 좋은 모델 학습을 위한 기초

### 1.1 과적합

학습 데이터의 오차가 일반적인 오차에 비해서 현격하게 낮아지는 현상

*underfitting* : 너무 학습이 덜된 현상

일반적으로<br>
1. 학습데이터는 부족한데<br>
2. 모델의 파라미터가 많은 상황에서<br>
과적합이 일어난다.

### 1.2 편향과 분산

모델의 복잡성이 증가하면

1. 분산은 증가
2. 편향은 감소

모델의 복잡성이 감소하면

1. 분산은 감소
2. 편향은 증가

---
#### <ins>편향과 분산 사이의 관계</ins>

*trade off 관계이다.*

![Alt text](\..\img\DL3-1.png)

이 최소값을 찾는 것은 어려운 작업

적절한 복잡성을 가진 모델을 선택해서, test data에 대한 성능을 최대화하는게 좋다.

## 2. 네트워크 안정화 기법

### 2.1 드롭아웃

모델 학습 시, 임의의 가중치 노드를 일정 확률로 비활성화 시키는 방법

학습이 잘 된 모델이면, 임의의 노드를 비활성화 해도 여전히 좋은 성능을 유지할 것이라고 예상

(일부러 noise를 주는 방법임)

<mark>앙상블 방법 중 하나이다.</mark>

> 앙상블은 개별적으로 학습시킨 여러 모델의 결과를 종합해서 추론하는 방식

### 2.2 정규화

#### <ins>피처 스케일링</ins>

서로 다른 입력 데이터의 값을 일정한 범위로 맞추는 작업

>ex. A : [10 ~ 100], B : [0 ~ 1000] $\Rightarrow$ A : [0 ~ 1], B : [0 ~ 1]

범위를 맞춤으로써 모든 특징을 편향없이 학습할 수 있게 된다.

---
#### <ins>여러가지 정규화 방법들</ins>

<ins>배치 정규화</ins>

배치 단위의 데이터를 기준으로 평균과 분산을 계산하여 **활성화 레이어 이후 출력을 정규화**

활성화 함수를 지남에 따라, 각 layer에 입력되는 값은 점점 더 줄어들게 됨<br>
(sigmoid 함수의 특성에 따라서)

따라서 이를 보완하기 위해 배치 정규화를 하게 된다.

완전 연결 레이어 이후, 활성화 함수를 적용하기 전에 적용한다.

---
<ins>레이어 정규화</ins>

배치 정규화의 단점을 보완한 방법<br>
배치 정규화는 텍스트같은 시계열 데이터에서 활용하기 때문에, RNN이나 LSTM에서 사용하기 어렵다.

(배치의 크기가 작은 경우, 전체 데이터 셋에 대한 정보를 반영하기 어렵다.)

하나의 layer에 대해 정규화를 진행하며, data의 크기가 달라도 정규화를 할 수 있다.

개별 데이터 sample에서 모든 특징들의 mean과 variance를 계산해서 정규화

---
<ins>인스턴스 정규화</ins>

각 데이터 샘플의 각 channel에서 평균과 분산을 계산해서 정규화

이미지 스타일 변환 같은 분야에서 데이터의 고유 정보를 유지하기 위해 사용

---
<ins>그룹 정규화</ins>

채널을 그룹핑 후, 그룹 내에서 mean과 variance를 계산해서 정규화하는 방법

인스턴스 정규화의 확장 버전으로 배치 사이즈가 작아도 잘 작동하는 방법을 제안


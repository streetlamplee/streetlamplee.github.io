---
layout: post
title: NLP 6. 자연어 처리를 위한 모델 학습
date: 2024-01-03 17:00 +0900
last_modified_at: 2024-01-03 17:00:00 +0900
tags: [NLP]
toc:  true
---

# 자연어처리를 위한 모델 학습

## 사전학습

원하는 자연어처리 작업을 수행하는 dataset으로 모델을 학습시키기 이전에 일반적인 데이터에 먼저 학습을 시키는 것

모델의 initializing 에서 사전학습 모델의 파라미터를 사용하면 더 높은 성능을 가진다.

* Computer Vision : ImageNet의 사전학습 모델을 이용
* NLP : GPT, BERT의 사전학습 모델을 이용한다.

---

#### ELMO

bi-LSTM 구조를 이용해서, 순방향과 역방향 언어모델을 각각 학습해서 임베딩 값을 얻음<br>
$\rightarrow$ 한 단어에 여러 의미가 있어도, 임베딩 값이 달라진다.

*한계점*

1. 고정된 크기의 벡터에 모든 정보를 압축하다보니 정보 손실 발생
2. RNN 구조의 문제 : Vanishing Gradient Problem<br>
문장의 길이가 길어지면, 초기 셀에서 전달했던 정보가 흐려짐
3. 입력을 순차적으로 처리해서 병렬화가 불가능
4. 사전학습된 언어 모델, Transformer<br>
어텐션 메커니즘만 사용하는 모델 구조 제안<br>
이를 기점으로 사전학습 효과가 증가하면서, 전이학습 패러다임이 활발해짐<br>
자연어 이외의 부문도 SOTA 모델로 자리잡음

> Q. 모델이 효율적으로 바뀌면서 왜 전이학습으로 패러다임이 바뀌었나?
>
> 큰 데이터의 다양한 정보들을 어텐션 메커니즘으로 효율 + 효과적으로 압축
>
> 더 큰 데이터의 일반화 정보를 학습해서 사전학습 효율이 높아짐

ex. <br>
Masked Language Modeling(MLM)<br>
input token에서 일정 비율을 마스킹하고, 마스킹한 토큰을 예측하는 과정

Next Token Prediction<br>
다음 토큰의 likelihood를 최대화하도록 표준 언어 모델링을 목적함수로 사용

### 사전 학습의 효과

1. 광범위한 데이터에서 일반적인 지식 학습
2. 모델의 Robustness 및 Uncertainty를 개선

## 전이학습

데이터가 아주 많은 도메인에서 학습된 지식을 데이터가 적은 도메인으로 전이시키는 학습 방법론

= 대규모 데이터와 일반화된 목적함수로 모델을 미리 학습하고, 해당 모델의 파라미터로 원하는 NLP 작업을 학습할 때, 모델을 최적화하는 학습방법

random으로 초기화된 모델에서 최적화를 시작하는 것은, noise와 gradient decent의 한계로 어렵다.

다만 미리 대규모 데이터로 학습된 것은 이런 문제를 어느정도 해결해줄 수 있을 것

---

#### 효과

1. 효율적인 학습 가능<br>
학습 초기 입력 데이터에 대한 특징을 추출하기 위한 시행착오를 생략
2. 학습 데이터셋에 대한 overfitting 방지<br>
작은 데이터셋에 대한 학습은 필연적인 overfitting 위험이 있으나, 이미 대용량 데이터를 사전학습해서 이를 막을 수 있다.
3. 부족한 도메인 지식 확보<br>
실제 target domain의 데이터 분포가 조금 다를 수 있고, 이럴 땐 해당 분야의 사전학습을 더 진행하는 것이 성능에 더 도움이 된다.
---

#### 주의사항

1. 사전 학습에 사용한 데이터와 새로 학습할 데이터가 비슷한 특징을 가지고 있어야한다.
2. 일반적으로 내가 새롭게 학습할 데이터보다 더 방대한 데이터로 사전 학습이 수행되어야한다.

## fine tuning

*사전 학습 (Pre-training)* : 원하는 NLP 작업을 수행하는 데이터 셋으로 모델을 **학습하기 전에** 일반적인 데이터에 먼저 학습을 시키는 것

*전이 학습 (transfer Learning)* : 대규모 데이터로 미리 사전학습한 모델의 파라미터로 내가 원하는 NLP 작업 학습 시, 사용 모델을 최적화하는 방법

**fine-tuning** : <br>사전 학습된 모델의 일반화된 지식을 활용하여 내가 원하는 NLP작업(downstream)을 학습하는 학습방법<br>
모델을 학습할 때, 사전 학습모델의 모든 parameter에 더불어, downstream 작업을 수행하기 위한 최소의 파라미터를 추가해서 모델 학습

---

#### 효과

DL 모델은 데이터 셋 내 특징을 **스스로** 학습한다.

모델의 low-level layer일수록 **일반적인** 특징을 학습하고,<br>
모델의 마지막 layer에 가까워질수록 **구체적인** 특징을 학습한다.

따라서 fine-tuning은 비슷한 특징을 가지고 있는 새로운 데이터 셋에 대해서 이미 학습에 유용한 특징을 추출 가능

---

#### 언어 모델의 fine tuning

BERT나 GPT도 대규모 자연어 코퍼스에서 사전학습 모델을 이용한 파인튜닝 전략으로 성능 개선

**GPT**

next token prediction으로 모델링 됨<br>
downstream 작업과 input의 모양이 다를 수 밖에 없다.

task 별 input 변형
1. classification : 분류하고자하는 모델을 GPT-1에 넣고, 마지막 토큰의 output을 classification layer에 입력
2. entailment :  Premise Hypothesis의 형태로 입력, 마지막 토큰의 output을 linear layer에 입력
3. similarity : 문장의 순서를 바꿔 두번 입력으로 넣고, 마지막 토큰의 output을 element-wise sum하여 linear layer에 입력
4. multiple choice : context를 먼저 넣고, answer를 뒤에 넣어 얻은 마지막 토큰의 output을 linear와 softmax layer에 입력

**BERT**

Transformer의 Self-attention 메커니즘으로 인해 쉽게 모델링 가능

1. Question Answering $\rightarrow$ (question, answer) pairs
2. Paraphrasing $\rightarrow$ (origin, paraphrased) pairs



## fine tuning 기법 (1)

방법 3가지

1. 모델 전체를 새로 학습
2. 모델 전체를 freezing, 새 layer 추가
3. 모델 일부를 freezing, 나머지는 tuning

**모델 freezing이란**

해당 모델의 layer의 파라미터를 학습과정 중에 최적화하지 않겠다는 의미

사전학습 모델의 피처 정보를 온전히 유지하기 위해 사용<br>
(주로 transfer learning)

---

#### 상황 1. 데이터 크기 큼, 사전학습 데이터 유사도 낮음

**전체 모델을 새로 학습**

데이터 크기가 커서, overfitting의 위험도 없음<br>
(단, 컴퓨팅 성능이 받쳐줘야함)

#### 상황 2. 데이터 크기 작임, 사전학습 데이터 유사도 높음

어떤 선택을 해도 상관이 없으나, **일부 freezing, 나머지 tuning**이 유효할 수 있다.

데이터가 커서, overfitting 문제는 없지만, 유사도가 높아 사전 학습 지식을 활용할 수 있다.

#### 상황 3. 데이터 크기 작음, 사전학습 데이터 유사도 낮음

유사성이 작아 사전학습 모델이 의미가 없을 수 있으나,<br>
차라리 overfitting 보다는 **사전 학습된 지식을 활용하는 것을 기대**해야 한다.

따라서 **일부 freezing, 나머지 tuning**이 유효할 수 있다.

#### 상황 4. 데이터 크기 작음, 사전학습 데이터 유사도 높음

**모델 전체 freezing, 새 layer 추가 학습**

유사도가 높으므로 사전 학습 지식을 최대한 활용해야함

혹은 성능 비교를 위해 사전 학습모델의 layer의 일부를 점점 unfreezing하는 것도 방법이다

---

최신 모델 tuning 기법

1. Adapter tuning
2. Pre-fix tuning
3. In-context learning
4. FL-tuning

## fine tuning 기법 (2)

#### fine tuning의 불안정성

BERT와 같은 transformer 기반 사전학습 모델의 파인튜닝은 불안정하다

*불안정한 학습??* :<br>
같은 데이터 셋에 대해서 같은 모델로 학습할 때, random_seed를 바꿔가며 여러 번 파인튜닝할 때 보이는 모델의 성능의 편차가 큰 상황을 말함

*왜 불안정해지는가?*
1. 가설 : Catastrophic forgetting<br>
하나의 신경망 네트워크가 두가지 서로 다른 task에 대해 순차적으로 훈련될 때 발생<br>
한 데이터 셋을 먼저 학습하고, 이후에 학습을 하면, 먼저 학습한 데이터를 해결하는 능력을 잃어버리게 된다.<br>
**근데 검증해보니 불안정해지는 이유가 아니더라**
2. 가설 : Small Size of the Fine-tuning Dataset<br>
작은 훈련 데이터 셋<br>
1,000개 데이터, epoch=3 versus. 1,000개 데이터, epoch=(기존 모델 학습 epoch)<br>
해보니까 학습량이 많으면, 기존 모델 분산으로 수렴하지만, **학습량이 적을 때, 분산이 더 커지더라**<br>
$\rightarrow$ 학습의 불안정성은 학습량에 달려있다

*결국 불안정해지는 원인은*
1. 학습 초기 최적화의 어려움<br>
그래프에 그림을 그려서 확인을 해보니, 실패한 모델의 기울기는 항상 local optimum에 있었다.<br>
**Vanishing Gradient**
2. 학습 후 모델의 서로 다른 일반화<br>
random_seed에 따라 많이 성능이 차이나지만, 학습이 충분해지면 비슷한 성능으로 수렴하게 된다.<br>
<br>해소 방법<br>
작은 learning rate로 Bias Correctio를 수행해서 Vanishing Gradient 방지

#### 불안정성을 해결하는 방법

**하이퍼 파라미터 튜닝

사람이 조정해야하는 값

1. hidden layer의 차원수
2. dropout 비율
3. activation func
4. learning rate
5. Optimizer
6. Loss func
7. 학습량 (epoch, batch size)

*일반화 고려 관점에서*
1. Dropout<br>
모델 layer의 일부를 drop out하는 방법<br>
overfitting을 방지하면서, 특정 노드에 의존하지 않게 되서 일반화 성능이 좋아짐
2. Weight Decay<br>
학습 과정에서 가중치가 커지지 않게 페널티 부과

*학습 시 learning rate 조절*
1. learning rate scheduling<br>
학습 진행 상황에 따라 learning rate 조절<br>
학습 초기에 learning rate를 줄여 안정성을 확보하고, 이후에 크게 조정 가능
2. global gradient clipping<br>
gradient vanishing을 억제하는 방법<br>
기울기가 임계값을 넘지 않도록 값에 제한을 둔다.

## fine tuning된 모델 분석 및 평가

학습 단계 (1. 데이터 준비, 2. 데이터 전처리, 3. 모델링 및 학습) 못지 않게 평가 단계도 중요하다.

#### 평가 기준

1. **실제 데이터에 대한 예측**<br>
학습 데이터가 아닌, 실제 데이터에 대한 정확한 예측을 고려
2. **정확한 판단에 의한 예측**<br>
학습 데이터의 shortcut이나 편향으로 예측이 아니라, 실제로 중요히 고려되는 특징들로 정답을 예측해야 한다.
3. **위험한 상황들에 대한 올바른 예측**<br>
실제 환경에서 발생할 수 있는 예기치못한 입력이나 위험한 상황에 대한 올바른 정답을 예측해야한다.

---

#### 자연어처리 모델 평가

**자연어 분류 작업에서의 모델 평가**

1. 감성 분석 : 문장에 내포된 감정을 분류
2. 자연어 추론 : 전제와 가설이 있을 때, 가설의 참/거짓을 추론
3. 의도 분류 : 문장에 내포된 의도를 분류
4. 문장 및 문서 분류 : 문장/문서를 정해진 카테고리로 분류

평가지표 : 주로 **Confusion Matrix**기반 지표를 사용<br>
ex. accuracy, precision, recall, f1 score

* Accuracy : $\displaystyle\frac{TP+TN}{TP+TN+FP+FN}$<br>
*Error rate* : 1 - Accuracy<br>
class의 불균형이 있을 경우, 한 쪽으로만 예측하는 모델이 나올 수 있음
* Precision : $\displaystyle\frac{TP}{TP+FP}$<br>
모델이 positive라고 예측한 것 중에, 실제 positive의 비율<br>
negative를 positive라고 잘못 예측하면 안되는 상황에서 사용
* Recall : $\displaystyle\frac{TP}{TP+FN}$<br>
실제 positive 중, 모델이 positive로 예측한 비율<br>
positive를 negative라고 잘못 예측하면 안되는 상황에서 사용
* F1-score : $\displaystyle\frac{2\times Precision \times Recall}{Precision + Recall}$<br>
Recall과 Precision의 조화평균<br>
상호보완적인 평가지표 2개를 통해 전반적인 성능 검사

**자연어 생성 작업에서의 모델 평가**

1. 기계 번역 작업 : 원본 문장의 의미를 보존해서 다른 언어 문장 생성
2. 기계 독해 작업 : 주어진 문서에서 질문에 대한 답변 생성/질의응답
3. 요약 작업 : 주어진 문서의 의미를 보존하되, 더 짧은 문서 생성

평가지표 : 정량 평가를 위해선 정답으로 여기는 **reference 문장**이 있어야함

* PPL(Perplexity)<br>
생성 모델은 한 token 단위로 생성을 하는데, 이때 PPL은 선택된 token의 누적 확률을 기반으로 계산한다.<br>
N개의 토큰을 $\\{ w_1, w_2, w_3, \cdots w_N\\}$이라 할 때,<br><br>
$PPL(W)=\sqrt[3]{\frac{1}{P(w_1,w_2,w_3,\cdots,w_N)}}$<br>
모델이 reference 문장을 생성할 때 얼마나 헷갈렸는지 나타내는 지표<br>
따라서 **낮을수록** 모델이 확신을 가지고 생성했다고 해석하며, 원하는 방향으로 **학습이 잘 되었다**고 가정한다.

* BLEU(Bilingual Evaluation Understudy)<br>
가장 많은 자연어 생성모델의 정량평가 지표<br>
수식은 아래와 같다.<br><br>
$BLEU = min\left( 1, \frac{output\;length(예측문장)}{reference\;length(실제문장)}\right) \left( \displaystyle \Pi^4_{i=1} precision_i\right)^{\frac{1}{4}}$<br><br>
n-gram 단위로 정답 문장과의 일치도를 측정, 의미 고려 X<br>
같은 의미의 다른 단어, 단어 구성이 다르지만 말이 되는 문장의 경우 점수가 낮게 나와서 문장의 의미가 잘 반영되는 지표는 아니다.

* SSA(Sensible and Specificity Average)<br>
**Sensibleness** : 모델이 생성한 문장이 말이 되는지<br>
말이 안되면 0, 말이 되면 1<br>
**Specificity** : 문장이 얼마나 구체적인지<br>
구체적인 context를 포함하면 1<br>
이를 이용해서 문장의 점수를 0 ~ 2로 주는 방식

기본적으로 자연어 생성 작업을 엄밀히 평가하기 어려움

따라서 정량적인 지표만으로 평가하지 말고, 정성적으로 평가하는 과정이 필수적으로 있어야함
---
layout: post
title: NLP 2. 한국어 데이터 전처리
date: 2023-12-07 19:00 +0900
last_modified_at: 2023-12-07 19:00:00 +0900
tags: [NLP]
toc:  true
---

# 2. 한국어 데이터 전처리

## 자연어 코퍼스 수집

코퍼스 : 대량의 텍스트 데이터

1. 다양한 패턴의 데이터 필요
2. 데이터가 유의미한 규모로 확보 + 대표성

수집과정

1. 필요한 자연어 코퍼스 유형 결정
<br>
어떤문제를 어떻게 풀것인지
<br>
언어모델 확인
<br>
데이터 크기, 유형을 확인해야함

2. 자료를 탐색하고 코퍼스 수집
<br>
1) 공개된/벤치마크 데이터셋<br>
2) 웹 코퍼스 (크롤링) : 다양하고 대량의 데이터 but 편향적이며 사실이 아닌 데이터 존재<br>
3) 온라인 뉴스 기사 : 시인성 반영 but 저작권 이슈 + 품질보장 불가능<br>
4) 직접 구축 : 사람이 필요하므로 많은 리소스 필요<br>
5) 자동 생성 코퍼스 : AI를 이용해서 자동 생성한 코퍼스 (일부만)<br>

## 토큰화

토큰 : 최소 의미 단위

토큰화 : 원시 데이터를 유용한 데이터 문자열로 변환하는 프로세스

필요성

1. 언어 모델의 자연어 이해 능력 향상

2. 다양한 자연어를 효율적으로 표현 가능 : 총 토큰의 집합 -> 단어사전, 보통 사전의 크기를 5만 이하로

토큰화 방법

1. 문장 토큰화 : 토큰의 단위가 문장임. 적절하지 않음
2. 단어 토큰화 : 토큰의 단위가 단어. 영어에서는 사용이 가능하나, 한국어는 불가능 (교착어)<br>
> 한계점 : OOV(Out Of Vocabulary) 문제, 새로운 단어가 추가되면 단어 사전의 크기가 커짐
3. 문자 토큰화 : 단어 하나의 추론에 너무 많은 추론이 필요함
4. 서브워드 토큰화 : 문자 토큰화의 확장 버젼, 토큰의 단위를 n개의 문자로 정의

## 서브워드 토큰화

기존 토큰화의 한계

토큰의 단위를 너무 크게 정의하면 사전의 크기가 커지고 OOV 문제

너무 작게 정의하면 토큰의 정보량이 적어짐

subword : 우리가 정의하는 단어보다 더 작은 의미의 단위

하나의 단어가 더 작은 단위의 의미있는 여러 서브워드들의 조합으로 구성되는 경우가 많아서 이를 분리

희귀단어, 신조어에서 대처할 수 있음

**BPE(Byte Pair Encoding) 알고리즘**

코퍼스 내 단어의 등장 빈도에 따라 서브워드를 구축

1) 사전에 출현 빈도가 높은 (a, b) 쌍이 있을때, a 와 b가 각각 빈번하면 빠르게 분절
2) 사전에 출현 빈도가 높은 (a, b) 쌍이 있을때, a와 b가 각각 나오지 않으면 분절하지 않음


---
layout: post
title: Pytorch_í…ì„œ ì‹¤ìŠµ 1
date: 2023-12-26 17:00 +0900
last_modified_at: 2023-12-26 17:00:00 +0900
tags: [deeplearning, Pytorch, tensor]
toc:  true
---

# í…ì„œ ì¡°ì‘ (1)

### í™˜ê²½ ì„¤ì •
> PyTorch ì„¤ì¹˜ ë° ë¶ˆëŸ¬ì˜¤ê¸°


- íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸


```python
!pip install torch==2.0.1 # PyTorch ë¥¼ ê°€ì¥ ìµœê·¼ ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜
```

    Collecting torch==2.0.1
      Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m619.9/619.9 MB[0m [31m1.8 MB/s[0m eta [36m0:00:00[0m
    [?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.13.1)
    Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.5.0)
    Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)
    Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.2.1)
    Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)
    Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)
      Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21.0/21.0 MB[0m [31m41.7 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)
      Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m849.3/849.3 kB[0m [31m45.6 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)
      Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m11.8/11.8 MB[0m [31m55.2 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)
      Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m557.1/557.1 MB[0m [31m2.8 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)
      Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m317.1/317.1 MB[0m [31m4.1 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)
      Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m168.4/168.4 MB[0m [31m7.3 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)
      Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m54.6/54.6 MB[0m [31m13.2 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)
      Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m102.6/102.6 MB[0m [31m8.8 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)
      Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m173.2/173.2 MB[0m [31m5.6 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)
      Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m177.1/177.1 MB[0m [31m6.6 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)
      Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m98.6/98.6 kB[0m [31m7.6 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting triton==2.0.0 (from torch==2.0.1)
      Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m63.3/63.3 MB[0m [31m10.0 MB/s[0m eta [36m0:00:00[0m
    [?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (67.7.2)
    Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.42.0)
    Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.9)
    Collecting lit (from triton==2.0.0->torch==2.0.1)
      Downloading lit-17.0.6.tar.gz (153 kB)
    [2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m153.0/153.0 kB[0m [31m16.3 MB/s[0m eta [36m0:00:00[0m
    [?25h  Installing build dependencies ... [?25l[?25hdone
      Getting requirements to build wheel ... [?25l[?25hdone
      Installing backend dependencies ... [?25l[?25hdone
      Preparing metadata (pyproject.toml) ... [?25l[?25hdone
    Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.3)
    Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)
    Building wheels for collected packages: lit
      Building wheel for lit (pyproject.toml) ... [?25l[?25hdone
      Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=a2db675c407969af1bb77b5921c595377dd31dd22a83d4ac2f8ce6da2d296823
      Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a
    Successfully built lit
    Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch
      Attempting uninstall: triton
        Found existing installation: triton 2.1.0
        Uninstalling triton-2.1.0:
          Successfully uninstalled triton-2.1.0
      Attempting uninstall: torch
        Found existing installation: torch 2.1.0+cu121
        Uninstalling torch-2.1.0+cu121:
          Successfully uninstalled torch-2.1.0+cu121
    [31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
    torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.
    torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.
    torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.
    torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.[0m[31m
    [0mSuccessfully installed lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0
    


```python
import torch # PyTorch ë¶ˆëŸ¬ì˜¤ê¸°
import numpy as np # numpy ë¶ˆëŸ¬ì˜¤ê¸°
import warnings # ê²½ê³  ë¬¸êµ¬ ì œê±°
warnings.filterwarnings('ignore')
```

## 1. í…ì„œ ì´í•´í•˜ê¸°

- 1-1. í…ì„œë¥¼ ìƒì„±í•˜ê³  í…ì„œë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì´í•´ ë° ì‹¤ìŠµ
- 1-2. í…ì„œì—ì„œì˜ indexing ì´í•´ ë° ì‹¤ìŠµ


### 1-1 í…ì„œë¥¼ ìƒì„±í•˜ê³  í…ì„œë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì´í•´ ë° ì‹¤ìŠµ

> Random í•œ ê°’ì„ ê°€ì§€ëŠ” í…ì„œë¥¼ ìƒì„±í•˜ê³ , list ë‚˜ numpy array ê°™ì€ ë‹¤ì–‘í•œ í˜•íƒœì˜ ë°°ì—´ë“¤ì„ PyTorch ë¥¼ ì´ìš©í•˜ì—¬ í…ì„œë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì•Œì•„ë´…ë‹ˆë‹¤.


#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ê°’ì„ ë¬´ì‘ìœ„ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ë“¤
* rand :  0ê³¼ 1 ì‚¬ì´ì˜ ê· ì¼í•œ ë¶„í¬ (Uniform Distribution) ì—ì„œ ë¬´ì‘ìœ„ë¡œ ìƒì„±ëœ í…ì„œë¥¼ ë°˜í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [rand] https://pytorch.org/docs/stable/generated/torch.rand.html


```python
# 0ë¶€í„° 1 ì‚¬ì´ì˜ ê°’ì„ ëœë¤í•˜ê²Œ NxM í…ì„œë¡œ ë°˜í™˜
torch.rand(2, 3) # torch.rand(NxM) NxMì€ í…ì„œì˜ í¬ê¸°ë¥¼ ë§í•©ë‹ˆë‹¤.
```




    tensor([[0.4832, 0.6079, 0.0965],
            [0.9239, 0.1382, 0.7564]])



#### ğŸ“ ì„¤ëª… : Tensor ì˜ ê°’ì„ ë¬´ì‘ìœ„ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ë“¤
* randn : í‰ê· ì´ 0ì´ê³  í‘œì¤€ í¸ì°¨ê°€ 1ì¸ ì •ê·œ ë¶„í¬(ê°€ìš°ì‹œì•ˆ ë¶„í¬)ì—ì„œ ë¬´ì‘ìœ„ë¡œ ìƒì„±ëœ í…ì„œë¥¼ ë°˜í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [randn] https://pytorch.org/docs/stable/generated/torch.randn.html


```python
# ê°€ìš°ì‹œì•ˆ ë¶„í¬ì—ì„œ ë Œë¤í•˜ê²Œ ê°’ì„ ì¶”ì¶œ í›„, NxM í…ì„œë¡œ ë°˜í™˜
torch.randn(2, 3) # torch.randn(NxM) NxMì€ í…ì„œì˜ í¬ê¸°ë¥¼ ë§í•©ë‹ˆë‹¤.
```




    tensor([[ 0.9027, -0.4474, -0.5633],
            [ 1.6880,  0.0257,  0.3113]])



#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ê°’ì„ ë¬´ì‘ìœ„ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ë“¤

* randint : ì£¼ì–´ì§„ ë²”ìœ„ ë‚´ì—ì„œ ì •ìˆ˜ê°’ì„ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•˜ì—¬ í…ì„œë¥¼ ìƒì„± (ë‹¨, ìµœì†Ÿê°’ì„ í¬í•¨í•˜ê³ , ìµœëŒ“ê°’ì€ í¬í•¨í•˜ì§€ ì•ŠìŒ)

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:

* [randint] https://pytorch.org/docs/stable/generated/torch.randint.html


```python
# ë²”ìœ„ ë‚´ì˜ ì •ìˆ˜ë¥¼ N x M í…ì„œë¡œ ë°˜í™˜
torch.randint(1, 10, (5, 5)) # ìƒì„± ê°€ëŠ¥í•œ ìµœì†Ÿê°’ : 1, ìµœëŒ“ê°’ : 9, (5x5) Tensor í¬ê¸°
```




    tensor([[9, 1, 3, 9, 2],
            [6, 9, 7, 2, 5],
            [4, 9, 4, 7, 1],
            [3, 4, 1, 7, 7],
            [3, 8, 1, 3, 1]])



#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ê°’ì„ ì§€ì •í•´ì„œ ìƒì„±í•˜ëŠ” ë°©ë²•ë“¤
* zeros : ëª¨ë“  ìš”ì†Œê°€ 0ì¸ í…ì„œ ë°˜í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [zeros] https://pytorch.org/docs/stable/generated/torch.zeros.html


```python
torch.zeros(3, 3) # torch.zeros(*size) ì—¬ê¸°ì„œ size ëŠ” ","ë¡œ êµ¬ë¶„í•˜ë©° ì°¨ì›ì„ ì—¬ëŸ¬ê°œë¡œ ëŠ˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```




    tensor([[0., 0., 0.],
            [0., 0., 0.],
            [0., 0., 0.]])



#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ê°’ì„ ì§€ì •í•´ì„œ ìƒì„±í•˜ëŠ” ë°©ë²•ë“¤
* ones : ëª¨ë“  ìš”ì†Œê°€ 1ì¸ í…ì„œ ë°˜í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [ones] https://pytorch.org/docs/stable/generated/torch.ones.html


```python
torch.ones(2, 2, 2) # torch.ones(*size) ì—¬ê¸°ì„œ size ëŠ” ","ë¡œ êµ¬ë¶„í•˜ë©° ì±„ë„ì„ ì—¬ëŸ¬ê°œë¡œ ëŠ˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```




    tensor([[[1., 1.],
             [1., 1.]],
    
            [[1., 1.],
             [1., 1.]]])



#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ê°’ì„ ì§€ì •í•´ì„œ ìƒì„±í•˜ëŠ” ë°©ë²•ë“¤
* full: ëª¨ë“  ìš”ì†Œê°€ ì§€ì •ëœ ê°’ì¸ í…ì„œ ë°˜í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [full] https://pytorch.org/docs/stable/generated/torch.full.html


```python
torch.full((2, 3), 5) # torch.full((size),value) => ê´„í˜¸ë¡œ í…ì„œì˜ í¬ê¸° (2,3) ë¥¼ ì…ë ¥í•˜ê³ , ì§€ì •í•œ ê°’ value (5) ë¡œ ëª¨ë“  ìš”ì†Œê°€ ì„¤ì •ë©ë‹ˆë‹¤.
```




    tensor([[5, 5, 5],
            [5, 5, 5]])



#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ê°’ì„ ì§€ì •í•´ì„œ ìƒì„±í•˜ëŠ” ë°©ë²•ë“¤
* eye : ë‹¨ìœ„ í–‰ë ¬ ë°˜í™˜ (â€» ë‹¨ìœ„ í–‰ë ¬ì´ë€? ëŒ€ê°ì„  ìš”ì†Œê°€ 1ì´ê³ , ë‚˜ë¨¸ì§€ ìš”ì†Œê°€ 0ì¸ í–‰ë ¬)

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [eye] https://pytorch.org/docs/stable/generated/torch.eye.html


```python
torch.eye(3) # torch.eye(n) (nxn) í¬ê¸°ë¥¼ ê°€ì§€ëŠ” ë‹¨ìœ„ í–‰ë ¬ ë°˜í™˜, ë‹¨ìœ„í–‰ë ¬ íŠ¹ì„± ìƒ ì •ì‚¬ê°í–‰ë ¬ (square matrix)ë§Œ ê°€ëŠ¥
```




    tensor([[1., 0., 0.],
            [0., 1., 0.],
            [0., 0., 1.]])



#### ğŸ“ ì„¤ëª… : ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ í…ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê¸°
* tensor : ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜. ë°ì´í„°ëŠ” list, tuple, numpy array ë“±ì˜ í˜•íƒœì¼ ìˆ˜ ìˆìŒ.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [tensor] https://pytorch.org/docs/stable/generated/torch.tensor.html


```python
# list, tuple, numpy arrayë¥¼ í…ì„œë¡œ ë°”ê¾¸ê¸°
ls = [[1, 2, 3, 4, 5],[6, 7, 8, 9, 10]] # sample list ìƒì„±
tup = tuple([1, 2, 3]) # sample tuple ìƒì„±
arr = np.array([[[1, 2, 3],[4, 5, 6]],[[7, 8, 9],[10, 11, 12]]]) # sample numpy array ìƒì„±

print(torch.tensor(ls))
print('\n')
print(torch.tensor(tup))
print('\n')
print(torch.tensor(arr))
```

    tensor([[ 1,  2,  3,  4,  5],
            [ 6,  7,  8,  9, 10]])
    
    
    tensor([1, 2, 3])
    
    
    tensor([[[ 1,  2,  3],
             [ 4,  5,  6]],
    
            [[ 7,  8,  9],
             [10, 11, 12]]])
    

#### ğŸ“ ì„¤ëª… : ë‹¤ì–‘í•œ í˜•íƒœë¥¼ í…ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê¸°
* from_numpy : numpy array ë¥¼ í…ì„œë¡œ ë³€í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [from_numpy] https://pytorch.org/docs/stable/generated/torch.from_numpy.html


```python
torch.from_numpy(arr) # array ë¥¼ tensorë¡œ ë°”ê¾¸ê¸° (2)
```




    tensor([[[ 1,  2,  3],
             [ 4,  5,  6]],
    
            [[ 7,  8,  9],
             [10, 11, 12]]])



#### ğŸ“ ì„¤ëª…: ë‹¤ì–‘í•œ í˜•ì‹ì˜ í…ì„œ ë³€í™˜
* as_tensor: ë³€í™˜ ì „ ë°ì´í„°ì™€ì˜ ë©”ëª¨ë¦¬ ê³µìœ (memory sharing)ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ë³€í™˜ ì „ ë°ì´í„° ë³€ê²½ ì‹œ ë³€í™˜ë˜ì–´ ìˆëŠ” í…ì„œì—ë„ ë°˜ì˜ë¨

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [as_tensor] https://pytorch.org/docs/stable/generated/torch.as_tensor.html


```python
# torch.tensor ì™€ torch.as_tensor ì˜ ì°¨ì´ì  ì•Œì•„ë³´ê¸°
print("torch.tensor")
data1 = np.array([1, 2, 3, 4, 5]) # ìƒ˜í”Œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ìƒì„±
tensor1 = torch.tensor(data1) # memory ê³µìœ  X
data1[0] = 10  # ì›ë³¸ ë°ì´í„° ë³€ê²½
print(tensor1)  # ì›ë³¸ ë°ì´í„°ì˜ ê°’ ë³€ê²½ì— ì˜í–¥ì„ ë°›ì§€ ì•ŠìŒ

print('-------'*10)

print("torch.as_tensor")
data2 = np.array([1, 2, 3, 4, 5])
tensor2 = torch.as_tensor(data2) # memory ê³µìœ  O
data2[0] = 10  # ì›ë³¸ ë°ì´í„° ë³€ê²½
print(tensor2)  # ì›ë³¸ ë°ì´í„°ì˜ ê°’ ë³€ê²½ì— ì˜í–¥ì„ ë°›ìŒ
```

    torch.tensor
    tensor([1, 2, 3, 4, 5])
    ----------------------------------------------------------------------
    torch.as_tensor
    tensor([10,  2,  3,  4,  5])
    

#### ğŸ“ ì„¤ëª… : ë‹¤ì–‘í•œ í˜•ì‹ì˜ í…ì„œ ë³€í™˜
* Tensor : **float32** typeìœ¼ë¡œ í…ì„œ ë³€í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [Tensor] https://pytorch.org/docs/stable/tensors.html


```python
data = [1, 2, 3, 4, 5]
tensor1 = torch.tensor(data) # list ì—ì„œ Tensor ë³€í™˜
print("torch.tensor")
print("Output:", tensor1)
print("Type", tensor1.dtype) # dtype : Tensor ì•ˆì˜ ì›ì†Œë“¤ì˜ ìë£Œí˜•, torch.tensor ëŠ” ì›ë³¸ì˜ ë°ì´í„° íƒ€ì…ì„ ê·¸ëŒ€ë¡œ ë”°ë¼ê°

print('-------'*3)

tensor2 = torch.Tensor(data) # list ì—ì„œ Tensor ë³€í™˜
print("torch.Tensor")
print("Output:", tensor2)
print("Type", tensor2.dtype) # torch.tensor ëŠ” float32 íƒ€ì…ìœ¼ë¡œ Tensor ë³€í™˜
```

    torch.tensor
    Output: tensor([1, 2, 3, 4, 5])
    Type torch.int64
    ---------------------
    torch.Tensor
    Output: tensor([1., 2., 3., 4., 5.])
    Type torch.float32
    

### 1-2 í…ì„œì—ì„œì˜ Indexing ì„ ì´í•´ ë° ì‹¤ìŠµ

> Indexing ê°œë…ê³¼ Indexing ì„ í†µí•´ ê°’ì„ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì´í•´í•˜ê³  ì‹¤ìŠµí•©ë‹ˆë‹¤.

#### ğŸ“ ì„¤ëª… : Indexing ì´ë€?
Indexing ì€ í…ì„œ ë‚´ì˜ íŠ¹ì • **ìš”ì†Œ**ë¥¼ indexë¥¼ í†µí•´ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
* Indexing ê¸°ë³¸ : **ëŒ€ê´„í˜¸("[ ]")**ë¥¼ í†µí•´ ì´ë¤„ì§€ë©°, **":"** ëŠ” íŠ¹ì • ë²”ìœ„ì˜ ì ‘ê·¼ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [Tensor indexing] : https://pytorch.org/cppdocs/notes/tensor_indexing.html


```python
# 1ì°¨ì› í…ì„œì—ì„œ Indexing í•˜ê¸°
tmp_1dim = torch.tensor([i for i in range(10)]) # 0ë¶€í„° 9 ê¹Œì§€ì˜ ê°’ì„ ê°€ì§€ëŠ” 1ì°¨ì› í…ì„œ ìƒì„±

print(tmp_1dim[0]) # ì²«ë²ˆì§¸ ì›ì†Œ ê°’ ì¶”ì¶œ
print(tmp_1dim[5]) # 6ë²ˆì§¸ ì›ì†Œ ê°’ ì¶”ì¶œ
print(tmp_1dim[-1]) # -1 ë²ˆì§¸ ì›ì†Œ ê°’ (ë’¤ì—ì„œ ì²«ë²ˆì§¸) ì¶”ì¶œ
```

    tensor(0)
    tensor(5)
    tensor(9)
    


```python
# 3ì°¨ì› í…ì„œì—ì„œ Indexing í•˜ê¸°
tmp_3dim = torch.randn(4, 3, 2) # 4ì±„ë„, 3í–‰, 2ì—´
print("Shape : ", tmp_3dim.shape)
print(tmp_3dim)

print('-------'*8)

print(tmp_3dim[:,:,0].shape)
print(tmp_3dim[:,:,0]) # ì „ì²´ ì±„ë„ê³¼ ì „ì²´ í–‰ì—ì„œ 0ë²ˆì§¸ ì—´ë§Œ ì¶”ì¶œ

print('\n') # ì¤„ ë„ì›€

print(tmp_3dim[0,:,1].shape)
print(tmp_3dim[0,:,1])  # 0ë²ˆì§¸ ì±„ë„ì˜ ì „ì²´ í–‰ì—ì„œ 1ë²ˆì§¸ ì—´ë§Œ ì¶”ì¶œ
```

    Shape :  torch.Size([4, 3, 2])
    tensor([[[ 0.9144,  0.3184],
             [ 1.0496,  0.8238],
             [-1.2094,  1.1296]],
    
            [[ 0.8414, -0.5814],
             [ 1.1207, -0.7272],
             [-2.3303, -0.8834]],
    
            [[ 0.5461,  1.8506],
             [ 0.2818, -1.4328],
             [-1.5978, -2.4369]],
    
            [[ 1.6518,  1.2504],
             [-0.0586, -0.0322],
             [-0.1793,  0.2690]]])
    --------------------------------------------------------
    torch.Size([4, 3])
    tensor([[ 0.9144,  1.0496, -1.2094],
            [ 0.8414,  1.1207, -2.3303],
            [ 0.5461,  0.2818, -1.5978],
            [ 1.6518, -0.0586, -0.1793]])
    
    
    torch.Size([3])
    tensor([0.3184, 0.8238, 1.1296])
    

#### ğŸ“ ì„¤ëª… : Indexing ì´ë€?
* index_select : ì„ íƒí•œ ì°¨ì›ì—ì„œ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìš”ì†Œë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [index_select] : https://pytorch.org/docs/stable/generated/torch.index_select.html


```python
# index_select
tmp_2dim = torch.tensor([[i for i in range(10)],[i for i in range(10, 20)]])
print(tmp_2dim)

print('\n')

my_index = torch.tensor([0, 2]) # ì„ íƒí•˜ê³ ì í•˜ëŠ” index ëŠ” í…ì„œ í˜•íƒœì´ì–´ì•¼ í•¨.
torch.index_select(tmp_2dim, dim=1, index=my_index) # ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ 0ì—´ê³¼ 2ì—´ì„ ì¶”ì¶œ
```

    tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
            [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])
    
    
    




    tensor([[ 0,  2],
            [10, 12]])



#### ğŸ“ ì„¤ëª… : Indexing ì´ë€?
* Masking ì„ ì´ìš©í•œ Indexing : ì¡°ê±´ì— ë”°ë¥¸ í…ì„œì˜ ìš”ì†Œë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ ì¡°ê±´ì— ë§ëŠ” ìš”ì†Œë“¤ë§Œ ë°˜í™˜í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.


```python
# mask ë¥¼ ì´ìš©í•œ í…ì„œ Indexing (ì¡°ê±´ì— ë§ëŠ” ê°’ë§Œ ì¶”ì¶œ)
mask = tmp_2dim >= 5 # 5ë³´ë‹¤ í° í…ì„œë§Œ ì¶”ì¶œ
tmp_2dim[mask] # 1ì°¨ì› Tensor ë¡œ ë°˜í™˜
```




    tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])



#### ğŸ“ ì„¤ëª… : Indexing ì´ë€?
* masked_select : ì£¼ì–´ì§„ maskì— í•´ë‹¹í•˜ëŠ” ìš”ì†Œë“¤ì„ ì¶”ì¶œí•˜ì—¬ 1ì°¨ì›ìœ¼ë¡œ í¼ì¹œ ìƒˆë¡œìš´ í…ì„œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [masked_select] : https://pytorch.org/docs/stable/generated/torch.masked_select.html


```python
torch.masked_select(tmp_2dim, mask = mask) # tmp_2dim[tmp_2dim >= 5] ì™€ ë™ì¼
```




    tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])



#### ğŸ“ ì„¤ëª… : Indexing ì´ë€?
* take : ì£¼ì–´ì§„ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ì„œì—ì„œ ìš”ì†Œë¥¼ ì„ íƒí•˜ëŠ” í•¨ìˆ˜. ì¸ë±ìŠ¤ ë²ˆí˜¸ëŠ” í…ì„œë¥¼ 1ì°¨ì›ìœ¼ë¡œ ëŠ˜ë ¤ì¡Œì„ ë•Œ ê¸°ì¤€ìœ¼ë¡œ ì ‘ê·¼í•´ì•¼í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [take] : https://pytorch.org/docs/stable/generated/torch.take.html


```python
tmp_2dim = torch.tensor([[i for i in range(10)], [i for i in range(10, 20)]])
print(tmp_2dim)

print('\n')

my_index = torch.tensor([0, 15])
torch.take(tmp_2dim, index = my_index) # Tensorê°€ 1ì°¨ì›ìœ¼ë¡œ ëŠ˜ë ¤ì¡Œì„ ë•Œ ê¸°ì¤€ìœ¼ë¡œ index ë²ˆí˜¸ë¡œ ì ‘ê·¼
```

    tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
            [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])
    
    
    




    tensor([ 0, 15])



#### ğŸ“ ì„¤ëª… : Indexing ì´ë€?
* gather : ì£¼ì–´ì§„ ì°¨ì›ì—ì„œ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìš”ì†Œë“¤ì„ ì„ íƒí•˜ì—¬ ìƒˆë¡œìš´ í…ì„œë¥¼ ë°˜í™˜

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [gather] : https://pytorch.org/docs/stable/generated/torch.gather.html


```python
tmp_2dim = torch.tensor([[i for i in range(10)],[i for i in range(10,20)]])
print(tmp_2dim)

print('\n')

recon_index =  torch.tensor([[0 ,1],[9, 8]]) # 0ë²ˆì§¸ ê°’, 1ë²ˆ ì§¸ ê°’ì„ 0ë²ˆì§¸ í–‰ìœ¼ë¡œ ì„¤ì •í•˜ê³ , 9ë²ˆì§¸ ê°’, 8ë²ˆì§¸ ê°’ì„ 1ë²ˆì§¸ í–‰ìœ¼ë¡œ ì„¤ì •í•œë‹¤.
dim = 1 # ì—´ ê¸°ì¤€
print(recon_index)
print('\n')

torch.gather(tmp_2dim, dim = 1, index = recon_index) # dim =1 ì´ë¯€ë¡œ ì—´ ê¸°ì¤€, 0í–‰ 0ì—´, 0í–‰ 1ì—´ ì„ íƒ, 1í–‰ 9ì—´, 1í–‰ 8ì—´
```

    tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
            [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])
    
    
    tensor([[0, 1],
            [9, 8]])
    
    
    




    tensor([[ 0,  1],
            [19, 18]])



## 2. í…ì„œì˜ ëª¨ì–‘ ë°”ê¾¸ê¸°



### 2-1 í…ì„œì˜ shapeì„ ë°”ê¾¸ëŠ” ì—¬ëŸ¬ê°€ì§€ í•¨ìˆ˜ ì´í•´ ë° ì‹¤ìŠµ
> í…ì„œì˜ ëª¨ì–‘ì„ ììœ ìì¬ë¡œ ë°”ê¾¸ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ê³  ì‹¤ìŠµí•©ë‹ˆë‹¤.



#### ğŸ“ ì„¤ëª… : í…ì„œì˜ shape ë³€ê²½
í…ì„œì— ëŒ€í•œ ëª¨ì–‘ì„ ë³€ê²½í•˜ê¸° ìœ„í•´ ëª…ì‹¬í•´ì•¼ í•  ì ì€ í…ì„œì˜ í¬ê¸° (ìš”ì†Œì˜ ê°œìˆ˜)ëŠ” ìœ ì§€ë˜ì–´ì•¼ í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤.
* size : í…ì„œì˜ ëª¨ì–‘ì„ í™•ì¸í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [size] : https://pytorch.org/docs/stable/generated/torch.Tensor.size.html


```python
a = torch.randn(2, 3, 5) # random í•œ ê°’ì„ ê°€ì§„ (1,3,5) í…ì„œ ìƒì„±
a.size() # ì°¨ì› í¬ê¸° í™•ì¸
```




    torch.Size([2, 3, 5])




```python
a.shape # a.size() ì™€ ë™ì¼
```




    torch.Size([2, 3, 5])



#### ğŸ“ ì„¤ëª… : í…ì„œì˜ shape ë³€ê²½
* reshape : í…ì„œì˜ ëª¨ì–‘ì„ ë³€ê²½í•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [reshape] : https://pytorch.org/docs/stable/generated/torch.reshape.html


```python
# ëª¨ì–‘ ë³€ê²½
a = torch.randn(2, 3, 5) # (2,3,5) í¬ê¸°ë¥¼ ê°€ì§€ëŠ” í…ì„œ ìƒì„±
print(a)
print("Shape : ", a.size()) # í…ì„œ ëª¨ì–‘ ë°˜í™˜
print('\n')

reshape_a = a.reshape(5, 6) # 3ì°¨ì› í…ì„œë¥¼ 2ì°¨ì› í…ì„œë¡œ í¬ê¸° ë³€ê²½ (2,3,5) -> (5,6)
print(reshape_a)
print("Shape : ", reshape_a.size()) # ë³€ê²½í•œ í…ì„œ ëª¨ì–‘ ë°˜í™˜
```

    tensor([[[ 1.4395,  0.5985, -1.1691,  1.5279, -0.0985],
             [-2.0897,  2.5121,  0.0553,  0.2532,  1.1086],
             [-1.2554, -1.1751, -0.0270,  0.0227, -0.6094]],
    
            [[ 0.8175, -0.7804,  1.2114, -2.4871,  0.7790],
             [-0.4992, -0.0488,  1.5461, -0.1898, -1.0895],
             [ 0.0334,  2.3150, -1.0674, -0.8454, -0.4906]]])
    Shape :  torch.Size([2, 3, 5])
    
    
    tensor([[ 1.4395,  0.5985, -1.1691,  1.5279, -0.0985, -2.0897],
            [ 2.5121,  0.0553,  0.2532,  1.1086, -1.2554, -1.1751],
            [-0.0270,  0.0227, -0.6094,  0.8175, -0.7804,  1.2114],
            [-2.4871,  0.7790, -0.4992, -0.0488,  1.5461, -0.1898],
            [-1.0895,  0.0334,  2.3150, -1.0674, -0.8454, -0.4906]])
    Shape :  torch.Size([5, 6])
    


```python
# -1 ë¡œ ëª¨ì–‘ ìë™ ì„¤ì •
reshape_auto_a = a.reshape(3, -1) # (2,3,5) í¬ê¸°ë¥¼ ê°€ì§€ëŠ” Tensorë¥¼ (3,n)ì˜ ëª¨ì–‘ìœ¼ë¡œ ë³€ê²½, "-1" ë¡œ í¬ê¸° ìë™ ê³„ì‚°
print(reshape_auto_a.size()) # 2x3x5 = 3 x n ì˜ ë°©ì •ì‹ì„ í‘¸ëŠ” ë¬¸ì œë¡œ n ì´ ìë™ì„¤ì •
```

    torch.Size([3, 10])
    


```python
a.reshape(7, -1) #  2x3x5 = 3 x n ì˜ ë°©ì •ì‹ì˜ í•´ê°€ ì •ìˆ˜ê°€ ì•„ë‹ˆë©´ ì˜¤ë¥˜ ë°œìƒ
```


    ---------------------------------------------------------------------------

    RuntimeError                              Traceback (most recent call last)

    <ipython-input-26-7a4b40636089> in <cell line: 1>()
    ----> 1 a.reshape(7, -1) #  2x3x5 = 3 x n ì˜ ë°©ì •ì‹ì˜ í•´ê°€ ì •ìˆ˜ê°€ ì•„ë‹ˆë©´ ì˜¤ë¥˜ ë°œìƒ
    

    RuntimeError: shape '[7, -1]' is invalid for input of size 30


#### ğŸ“ ì„¤ëª… : í…ì„œì˜ shape ë³€ê²½
* view : í…ì„œì˜ ëª¨ì–‘ì„ ë³€ê²½í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [view] : https://pytorch.org/docs/stable/generated/torch.Tensor.view.html


```python
print(a)
print("Shape : ", a.size()) # í…ì„œ ëª¨ì–‘ ë°˜í™˜
print('\n')

view_a = a.view(5, 6) # reshape ê³¼ ë™ì¼í•˜ê²Œ (2,3,5) í¬ê¸°ë¥¼ (5,6) í¬ê¸°ë¡œ ë³€ê²½
print(view_a)
print("Shape : ", view_a.size())
```

    tensor([[[ 1.4395,  0.5985, -1.1691,  1.5279, -0.0985],
             [-2.0897,  2.5121,  0.0553,  0.2532,  1.1086],
             [-1.2554, -1.1751, -0.0270,  0.0227, -0.6094]],
    
            [[ 0.8175, -0.7804,  1.2114, -2.4871,  0.7790],
             [-0.4992, -0.0488,  1.5461, -0.1898, -1.0895],
             [ 0.0334,  2.3150, -1.0674, -0.8454, -0.4906]]])
    Shape :  torch.Size([2, 3, 5])
    
    
    tensor([[ 1.4395,  0.5985, -1.1691,  1.5279, -0.0985, -2.0897],
            [ 2.5121,  0.0553,  0.2532,  1.1086, -1.2554, -1.1751],
            [-0.0270,  0.0227, -0.6094,  0.8175, -0.7804,  1.2114],
            [-2.4871,  0.7790, -0.4992, -0.0488,  1.5461, -0.1898],
            [-1.0895,  0.0334,  2.3150, -1.0674, -0.8454, -0.4906]])
    Shape :  torch.Size([5, 6])
    


```python
view_auto_a = a.view(3, -1) # reshape ê³¼ ë™ì¼í•˜ê²Œ (3,n)ì˜ ëª¨ì–‘ìœ¼ë¡œ ë³€ê²½. "-1" ë¡œ í¬ê¸° ìë™ ê³„ì‚°
print(view_auto_a.size())
```

    torch.Size([3, 10])
    

#### ğŸ“ ì„¤ëª… : í…ì„œì˜ shape ë³€ê²½
* transpose : í…ì„œì˜ ì°¨ì›ì„ ì „ì¹˜í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [transpose] : https://pytorch.org/docs/stable/generated/torch.transpose.html


```python
tensor_a = torch.randint(1, 10, (3, 2, 5)) # 1 ~ 9ì˜ ê°’ì„ ê°€ì§€ëŠ” (3,2,5) ì‚¬ì´ì¦ˆì˜ Tensor ìƒì„±
print(tensor_a)
print("Shape : ", tensor_a.size())
print('\n')

# (3,2,5) ë¥¼ (2,3,5) ì˜ í¬ê¸°ë¡œ ë³€ê²½
trans_a = tensor_a.transpose(1, 2) # í–‰ê³¼ ì—´ì„ ì„œë¡œ ì „ì¹˜, ì„œë¡œ ì „ì¹˜í•  ì°¨ì› 2ê°œë¥¼ ì§€ì •
print(trans_a)
print("Shape : ", trans_a.size())
```

    tensor([[[2, 9, 8, 1, 5],
             [1, 4, 1, 7, 4]],
    
            [[3, 5, 2, 9, 9],
             [7, 8, 9, 1, 4]],
    
            [[4, 4, 6, 3, 4],
             [6, 9, 6, 2, 3]]])
    Shape :  torch.Size([3, 2, 5])
    
    
    tensor([[[2, 1],
             [9, 4],
             [8, 1],
             [1, 7],
             [5, 4]],
    
            [[3, 7],
             [5, 8],
             [2, 9],
             [9, 1],
             [9, 4]],
    
            [[4, 6],
             [4, 9],
             [6, 6],
             [3, 2],
             [4, 3]]])
    Shape :  torch.Size([3, 5, 2])
    

#### ğŸ“ ì„¤ëª… : í…ì„œì˜ shape ë³€ê²½
* permute : í…ì„œ ì°¨ì›ì˜ ìˆœì„œë¥¼ ì¬ë°°ì—´í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [permute] : https://pytorch.org/docs/stable/generated/torch.permute.html


```python
print(tensor_a)
print("Shape : ", tensor_a.size())
print('\n')

permute_a = tensor_a.permute(0, 2, 1) # (3,2,5)ì˜ ëª¨ì–‘ì„ (3,5,2)ì˜ ëª¨ì–‘ìœ¼ë¡œ ë³€ê²½
print(permute_a)
print("Shape : ", permute_a.size())
```

    tensor([[[2, 9, 8, 1, 5],
             [1, 4, 1, 7, 4]],
    
            [[3, 5, 2, 9, 9],
             [7, 8, 9, 1, 4]],
    
            [[4, 4, 6, 3, 4],
             [6, 9, 6, 2, 3]]])
    Shape :  torch.Size([3, 2, 5])
    
    
    tensor([[[2, 1],
             [9, 4],
             [8, 1],
             [1, 7],
             [5, 4]],
    
            [[3, 7],
             [5, 8],
             [2, 9],
             [9, 1],
             [9, 4]],
    
            [[4, 6],
             [4, 9],
             [6, 6],
             [3, 2],
             [4, 3]]])
    Shape :  torch.Size([3, 5, 2])
    

### 2-2 í…ì„œì˜ ì°¨ì›ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ

#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ì°¨ì›ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ
* unsqueeze : í…ì„œì— íŠ¹ì • ì°¨ì›ì— í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [unsqueeze] : https://pytorch.org/docs/stable/generated/torch.unsqueeze.html


```python
tensor_a = torch.tensor([i for i in range(10)]).reshape(5, 2) # 0ë¶€í„° 9ê¹Œì§€ì˜ ìˆ«ìë“¤ì„ (5,2) í¬ê¸°ë¡œ ë³€ê²½
print(tensor_a)
print('Shape : ', tensor_a.size())
print('\n')

unsqu_a = tensor_a.unsqueeze(0) # 0ë²ˆì§¸ ì°¨ì› í•˜ë‚˜ ì¶”ê°€ (5,2) => (1,5,2)
print(unsqu_a)
print('Shape : ', unsqu_a.size())
```

    tensor([[0, 1],
            [2, 3],
            [4, 5],
            [6, 7],
            [8, 9]])
    Shape :  torch.Size([5, 2])
    
    
    tensor([[[0, 1],
             [2, 3],
             [4, 5],
             [6, 7],
             [8, 9]]])
    Shape :  torch.Size([1, 5, 2])
    


```python
unsqu_a2 = tensor_a.unsqueeze(-1) # ë§ˆì§€ë§‰ë²ˆì§¸ì— ì°¨ì› í•˜ë‚˜ ì¶”ê°€ (5,2) => (5,2,1)
print(unsqu_a2)
print('Shape : ', unsqu_a2.size())
```

    tensor([[[0],
             [1]],
    
            [[2],
             [3]],
    
            [[4],
             [5]],
    
            [[6],
             [7]],
    
            [[8],
             [9]]])
    Shape :  torch.Size([5, 2, 1])
    

#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ì°¨ì›ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ
* squeeze : í…ì„œì— ì°¨ì›ì˜ í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì œê±°í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [squeeze] : https://pytorch.org/docs/stable/generated/torch.squeeze.html


```python
print(unsqu_a)
print("Shape : ", unsqu_a.size())
print('\n')

squ = unsqu_a.squeeze() # ì°¨ì›ì´ 1ì¸ ì°¨ì›ì„ ì œê±°
print(squ)
print("Shape : ", squ.size())
```

    tensor([[[0, 1],
             [2, 3],
             [4, 5],
             [6, 7],
             [8, 9]]])
    Shape :  torch.Size([1, 5, 2])
    
    
    tensor([[0, 1],
            [2, 3],
            [4, 5],
            [6, 7],
            [8, 9]])
    Shape :  torch.Size([5, 2])
    


```python
x = torch.zeros(2, 1, 2, 1, 2) # ëª¨ë“  ì›ì†Œê°€ 0ì¸ (2,1,2,1,2) í¬ê¸°ë¥¼ ê°€ì§€ëŠ” í…ì„œ
print("Shape (original) : ", x.size()) # ì›ë˜ í…ì„œ í¬ê¸°
print('\n')

print("Shape (squeeze()) :", x.squeeze().size()) # ì°¨ì›ì´ 1ì¸ ì°¨ì›ì´ ì—¬ëŸ¬ê°œì¼ ë•Œ, ëª¨ë“  ì°¨ì›ì´ 1ì¸ ì°¨ì› ì œê±°
print('\n')

print("Shape (squeeze(0)) :", x.squeeze(0).size()) # 0ë²ˆì§¸ ì°¨ì›ì€ ì°¨ì›ì˜ í¬ê¸°ê°€ 1ì´ ì•„ë‹ˆë¯€ë¡œ, ë³€í™” ì—†ìŒ
print('\n')

print("Shape (squeeze(1)) :", x.squeeze(1).size()) # 1ë²ˆì§¸ ì°¨ì›ì€ ì°¨ì›ì˜ í¬ê¸°ê°€ 1ì´ë¯€ë¡œ ì œê±°
print('\n')

print("Shape (squeeze(0,1,3)) :", x.squeeze((0, 1, 3)).size()) # ì—¬ëŸ¬ ì°¨ì› ì œê±° ê°€ëŠ¥ (0ë²ˆì§¸ ì°¨ì›ì€ ì°¨ì›ì˜ í¬ê¸°ê°€ 1ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ë¬´ì‹œ)
```

    Shape (original) :  torch.Size([2, 1, 2, 1, 2])
    
    
    Shape (squeeze()) : torch.Size([2, 2, 2])
    
    
    Shape (squeeze(0)) : torch.Size([2, 1, 2, 1, 2])
    
    
    Shape (squeeze(1)) : torch.Size([2, 2, 1, 2])
    
    
    Shape (squeeze(0,1,3)) : torch.Size([2, 2, 2])
    

#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ì°¨ì›ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ
* expand : í…ì„œì˜ ê°’ì„ ë°˜ë³µí•˜ì—¬ í¬ê¸°ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.
  * A í…ì„œê°€ 1ì°¨ì›ì¼ ê²½ìš° : A í…ì„œì˜ í¬ê¸°ê°€ (m,) ì´ë©´ mì€ ê³ ì •í•˜ê³  (x,m)ì˜ í¬ê¸°ë¡œë§Œ í™•ì¥ ê°€ëŠ¥
  * A í…ì„œê°€ 2ì°¨ì› ì´ìƒì¼ ê²½ìš° : í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì— ëŒ€í•´ì„œë§Œ ì ìš© ê°€ëŠ¥. A í…ì„œì˜ í¬ê¸°ê°€ (1,m) ì´ë©´ (x,m) , (m,1) ì´ë©´ (m,y) ë¡œë§Œ í™•ì¥ ê°€ëŠ¥.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [expand] : https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html



```python
tensor_1dim = torch.tensor([1, 2, 3, 4])
print(tensor_1dim)
print("Shape : ", tensor_1dim.size())
print('\n')

expand_tensor = tensor_1dim.expand(3, 4) # (,4) ë¥¼ (3,4) ì˜ í¬ê¸°ë¡œ í™•ì¥ (ê°’ì„ ë°˜ë³µ)
print(expand_tensor)
print("Shape : ", expand_tensor.size())
```

    tensor([1, 2, 3, 4])
    Shape :  torch.Size([4])
    
    
    tensor([[1, 2, 3, 4],
            [1, 2, 3, 4],
            [1, 2, 3, 4]])
    Shape :  torch.Size([3, 4])
    


```python
tensor_2dim = torch.tensor([[1, 2, 3, 4], [1, 2, 3, 4]]) # (2,4) í¬ê¸°ë¥¼ ê°€ì§„ Tensor
print(tensor_2dim)
print("Shape : ", tensor_2dim.size())
print('\n')

expand_tensor = tensor_2dim.expand(4,4) # (2,4) ë¥¼ (4,8) ì˜ í¬ê¸°ë¡œ í™•ì¥ (ê°’ì„ ë°˜ë³µ)
print(expand_tensor) # ì—ëŸ¬ ë°œìƒ
print("Shape : ", expand_tensor.size()) # ì—ëŸ¬ ë°œìƒ
```

    tensor([[1, 2, 3, 4],
            [1, 2, 3, 4]])
    Shape :  torch.Size([2, 4])
    
    
    


    ---------------------------------------------------------------------------

    RuntimeError                              Traceback (most recent call last)

    <ipython-input-36-ca0aa7093d8c> in <cell line: 6>()
          4 print('\n')
          5 
    ----> 6 expand_tensor = tensor_2dim.expand(4,4) # (2,4) ë¥¼ (4,8) ì˜ í¬ê¸°ë¡œ í™•ì¥ (ê°’ì„ ë°˜ë³µ)
          7 print(expand_tensor) # ì—ëŸ¬ ë°œìƒ
          8 print("Shape : ", expand_tensor.size()) # ì—ëŸ¬ ë°œìƒ
    

    RuntimeError: The expanded size of the tensor (4) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [4, 4].  Tensor sizes: [2, 4]


#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ì°¨ì›ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ
* repeat : í…ì„œë¥¼ ë°˜ë³µí•˜ì—¬ í¬ê¸°ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.
  * ex) A í…ì„œê°€ (m,n) í¬ê¸°ë¥¼ ê°€ì§„ë‹¤í•˜ê³ , A í…ì„œë¥¼ repeat(i,j) ë¥¼ í•˜ë©´ ê²°ê³¼ê°’ìœ¼ë¡œ (m x i, n x j)ì˜ í¬ê¸°ì˜ í…ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [repeat] : https://pytorch.org/docs/stable/generated/torch.Tensor.repeat.html


```python
tensor_1dim = torch.tensor([1, 2, 3, 4])
print(tensor_1dim)
print("Shape : ", tensor_1dim.size())
print('\n')

repeat_tensor = tensor_1dim.repeat(3, 4) # tensor_1dim ìì²´ë¥¼ í–‰ìœ¼ë¡œ 3ë²ˆ ë°˜ë³µ, ì—´ë¡œ 4ë²ˆ ë°˜ë³µ
print(repeat_tensor)
print("Shape : ", repeat_tensor.size())
```

    tensor([1, 2, 3, 4])
    Shape :  torch.Size([4])
    
    
    tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],
            [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],
            [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]])
    Shape :  torch.Size([3, 16])
    

#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ì°¨ì›ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ
* flatten : ë‹¤ì°¨ì› í…ì„œë¥¼ 1ì°¨ì› í…ì„œë¡œ ë³€ê²½í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [flatten] : https://pytorch.org/docs/stable/generated/torch.flatten.html


```python
t = torch.tensor([i for i in range(20)]).reshape(2, 5, 2) # 0ë¶€í„° 19ê¹Œì§€ì˜ ìˆ«ìë¥¼ 4í–‰ 5ì—´ Tensorë¡œ êµ¬ì„±
print(t)
print("Shape : ", t.size())
print('\n')

flat_tensor = t.flatten() # (2, 5, 2) ì˜ Tensorë¥¼ (20,)ë¡œ ëª¨ì–‘ ë³€ê²½, 1ì°¨ì›ìœ¼ë¡œ ë³€ê²½
print(flat_tensor)
print("Shape : ", flat_tensor.size())
```

    tensor([[[ 0,  1],
             [ 2,  3],
             [ 4,  5],
             [ 6,  7],
             [ 8,  9]],
    
            [[10, 11],
             [12, 13],
             [14, 15],
             [16, 17],
             [18, 19]]])
    Shape :  torch.Size([2, 5, 2])
    
    
    tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
            18, 19])
    Shape :  torch.Size([20])
    


```python
flat_tensor2 = t.flatten(start_dim=1) # flattenì„ ì‹œì‘í•  ì°¨ì›ì„ ì§€ì •í•  ìˆ˜ ìˆìŒ. ì§€ì •í•œ ì°¨ì› ì´í›„ì˜ ëª¨ë“  ì°¨ì›ì„ í•˜ë‚˜ì˜ ì°¨ì›ìœ¼ë¡œ í‰ë©´í™”, ê¸°ë³¸ê°’ = 0 (1ì°¨ì›)
print(flat_tensor2)
print(flat_tensor2.size())
```

    tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
            [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])
    torch.Size([2, 10])
    

#### ğŸ“ ì„¤ëª… : í…ì„œì˜ ì°¨ì›ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ
* ravel : ë‹¤ì°¨ì› í…ì„œë¥¼ 1ì°¨ì› í…ì„œë¡œ ë³€ê²½í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [ravel] : https://pytorch.org/docs/stable/generated/torch.ravel.html


```python
t = torch.tensor([i for i in range(20)]).reshape(2, 5, 2) # 0ë¶€í„° 19ê¹Œì§€ì˜ ìˆ«ìë¥¼ (2, 5, 2) í¬ê¸° Tensorë¡œ êµ¬ì„±
print(t)
print("Shape : ", t.size())
print('\n')

ravel_tensor = t.ravel() # flatten ê³¼ ë™ì¼í•˜ê²Œ (2,5,2) ì˜ í…ì„œë¥¼ (20,)ë¡œ ëª¨ì–‘ ë³€ê²½, 1ì°¨ì›ìœ¼ë¡œ ë³€ê²½
print(ravel_tensor)
print("Shape : ", ravel_tensor.size())
```

    tensor([[[ 0,  1],
             [ 2,  3],
             [ 4,  5],
             [ 6,  7],
             [ 8,  9]],
    
            [[10, 11],
             [12, 13],
             [14, 15],
             [16, 17],
             [18, 19]]])
    Shape :  torch.Size([2, 5, 2])
    
    
    tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
            18, 19])
    Shape :  torch.Size([20])
    


```python
t.ravel(1) # ì—ëŸ¬ ë°œìƒ, ravel ì€ flatten ê³¼ ë‹¬ë¦¬ ì–´ë– í•œ ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ í‰íƒ„í™” í•˜ëŠ” ì‘ì—…ì´ ì—†ìŒ
```


    ---------------------------------------------------------------------------

    TypeError                                 Traceback (most recent call last)

    <ipython-input-41-4ad2f534a783> in <cell line: 1>()
    ----> 1 t.ravel(1) # ì—ëŸ¬ ë°œìƒ, ravel ì€ flatten ê³¼ ë‹¬ë¦¬ ì–´ë– í•œ ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ í‰íƒ„í™” í•˜ëŠ” ì‘ì—…ì´ ì—†ìŒ
    

    TypeError: _TensorBase.ravel() takes no arguments (1 given)


### 2-3 ì—­í• ì´ ë¹„ìŠ·í•œ í•¨ìˆ˜ë“¤ì˜ ì°¨ì´ ì´í•´ ë° ì‹¤ìŠµ
> ì—­í• ì´ ë¹„ìŠ·í•œ í•¨ìˆ˜ë“¤ì˜ ê³µí†µì ê³¼ ì°¨ì´ì ì„ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ğŸ“ ì„¤ëª… : ì—­í• ì´ ë¹„ìŠ·í•œ í•¨ìˆ˜ë“¤ì˜ ì°¨ì´ ì´í•´ ë° ì‹¤ìŠµ
* ëª¨ì–‘ ë³€ê²½ : view vs. reshape vs. unsqueeze
  * â€» contiguous ë€?
    * í…ì„œì˜ ë©”ëª¨ë¦¬ ìƒì— ì—°ì†ì ì¸ ë°ì´í„° ë°°ì¹˜ë¥¼ ê°–ëŠ” ê²ƒ
    * í…ì„œë¥¼ ì²˜ìŒ ìƒì„± í›„ ì •ì˜í•˜ë©´ ê¸°ë³¸ì ìœ¼ë¡œ contiguous í•˜ì§€ë§Œ, ì´ì— ëŒ€í•´ ì°¨ì›ì˜ ìˆœì„œë¥¼ ë³€ê²½í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ë©´ contiguous í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    * í…ì„œì˜ contiguous í•¨ì„ í™•ì¸í•˜ê¸° ìœ„í•´ì„  is_contiguous() ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
  * view ëŠ” contiguous í•˜ì§€ ì•Šì€ í…ì„œì— ëŒ€í•´ì„œ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
  * reshape ëŠ” contiguous í•˜ì§€ ì•Šì€ í…ì„œë¥¼ contiguous í•˜ê²Œ ë§Œë“¤ì–´ì£¼ê³ , í¬ê¸°ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.
  * unsqueeze ëŠ” ì°¨ì›ì˜ í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì¶”ê°€í•˜ì§€ë§Œ, ì°¨ì›ì˜ í¬ê¸°ê°€ 1ì´ ì•„ë‹ˆë©´ ì°¨ì›ì˜ ëª¨ì–‘ì„ ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [what is contiguous?] : https://titania7777.tistory.com/3
* [view vs reshape] :  https://inmoonlight.github.io/2021/03/03/PyTorch-view-transpose-reshape/
* [view, reshape, transpose, permute ë¹„êµ] : https://sanghyu.tistory.com/3


```python
# view vs reshape
tmp = torch.tensor([[[0, 1], [2, 3], [4, 5]], \
                 [[6, 7], [8, 9], [10, 11]], \
                 [[12, 13], [14, 15], [16, 17]], \
                 [[18, 19], [20, 21], [22, 23]]])
tmp_t = tmp.transpose(0,1) # contiguous ë¥¼ False ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì‘ì—…
print(tmp_t.is_contiguous()) # contiguous í•œì§€ ê²€ì‚¬
print(tmp_t.view(-1)) # viewëŠ” contiguous í•˜ì§€ ì•Šì€ í…ì„œì— ëŒ€í•´ì„  ë™ì‘ì´ ë˜ì§€ ì•ŠìŒ
```

    False
    


    ---------------------------------------------------------------------------

    RuntimeError                              Traceback (most recent call last)

    <ipython-input-42-58c86dac39d7> in <cell line: 8>()
          6 tmp_t = tmp.transpose(0,1) # contiguous ë¥¼ False ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì‘ì—…
          7 print(tmp_t.is_contiguous()) # contiguous í•œì§€ ê²€ì‚¬
    ----> 8 print(tmp_t.view(-1)) # viewëŠ” contiguous í•˜ì§€ ì•Šì€ í…ì„œì— ëŒ€í•´ì„  ë™ì‘ì´ ë˜ì§€ ì•ŠìŒ
    

    RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.



```python
reshape_tmp = tmp_t.reshape(-1) # reshapeì€ contiguous í•˜ì§€ ì•Šì•„ë„ ë™ì‘ì´ ë¨
print(reshape_tmp)
print(reshape_tmp.is_contiguous()) # contiguous í•˜ì§€ ì•Šì•˜ë˜ Tensorë¥¼ contiguous í•˜ê²Œ ë³€ê²½í•´ ì¤Œ
```

    tensor([ 0,  1,  6,  7, 12, 13, 18, 19,  2,  3,  8,  9, 14, 15, 20, 21,  4,  5,
            10, 11, 16, 17, 22, 23])
    True
    


```python
# (view , reshape) vs unsqueeze
tensor_a = torch.randn(2, 3)
# (2, 3) ì˜ í…ì„œë¥¼ (2, 3, 1)ì˜ í¬ê¸°ë¡œ ë³€ê²½
view_tensor = tensor_a.view(2, 3, 1) # view ë¥¼ ì´ìš©í•˜ì—¬ (2,3,1) ì˜ í¬ê¸°ë¡œ ë³€ê²½
reshape_tensor = tensor_a.reshape(2, 3, 1) # reshape ë¥¼ ì´ìš©í•˜ì—¬ (2,3,1) ì˜ í¬ê¸°ë¡œ ë³€ê²½
unsqueeze_tensor = tensor_a.unsqueeze(-1) # unsqueeze ë¥¼ ì´ìš©í•˜ì—¬ (2,3,1) ì˜ í¬ê¸°ë¡œ ë³€ê²½

print("View output size : ",view_tensor.size())
print("Reshape output size : ",reshape_tensor.size())
print("Unsqueeze output size : ",unsqueeze_tensor.size())
```

    View output size :  torch.Size([2, 3, 1])
    Reshape output size :  torch.Size([2, 3, 1])
    Unsqueeze output size :  torch.Size([2, 3, 1])
    

#### ğŸ“ ì„¤ëª… : ì—­í• ì´ ë¹„ìŠ·í•œ í•¨ìˆ˜ë“¤ì˜ ì°¨ì´ ì´í•´ ë° ì‹¤ìŠµ
* ì°¨ì› ë³€ê²½ : transpose vs. permute
  * transpose : ë‘ ì°¨ì›ì— ëŒ€í•´ì„œë§Œ ë³€ê²½ì´ ê°€ëŠ¥
    * ì¸ìê°€ ì´ 2ê°œì—¬ì•¼í•¨.
  * permute : ëª¨ë“  ì°¨ì›ì— ëŒ€í•´ì„œ ë³€ê²½ì´ ê°€ëŠ¥
    * ì¸ìê°€ ì°¨ì›ì˜ ê°œìˆ˜ì™€ ë™ì¼í•´ì•¼ í•¨.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [view, reshape, transpose, permute ë¹„êµ] : https://sanghyu.tistory.com/3


```python
import torch
tensor_a = torch.randn(2, 3, 2)
transpose_tensor = tensor_a.transpose(2, 1) # í–‰ê³¼ ì—´ì„ ì „ì¹˜
permute_tensor = tensor_a.permute(0, 2, 1) # í–‰ê³¼ ì—´ì„ ë°”ê¿ˆ.

print("Transpose tensor shape : ", transpose_tensor.size())
print("Permute tensor shape : ", permute_tensor.size())
```

    Transpose tensor shape :  torch.Size([2, 2, 3])
    Permute tensor shape :  torch.Size([2, 2, 3])
    

#### ğŸ“ ì„¤ëª… : ì—­í• ì´ ë¹„ìŠ·í•œ í•¨ìˆ˜ë“¤ì˜ ì°¨ì´ ì´í•´ ë° ì‹¤ìŠµ
* ë°˜ë³µì„ í†µí•œ í…ì„œ í¬ê¸° í™•ì¥ : expand vs. repeat
  * expand
    * ì›ë³¸ í…ì„œì™€ ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•œë‹¤.
  * repeat
    * ì›ë³¸ í…ì„œì™€ ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•˜ì§€ ì•ŠëŠ”ë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [expand vs repeat] : https://seducinghyeok.tistory.com/9


```python
import torch

# ì›ë³¸ í…ì„œ ìƒì„±
tensor_a = torch.rand(1, 1, 3)
print('Original Tensor Size')
print(tensor_a.size())
print(tensor_a)

print('\n')

# expand ì‚¬ìš©í•˜ì—¬ (1,1,3) => (4, 1, 3)
expand_tensor = tensor_a.expand(4, 1, -1)
print("Shape of expanded tensor:", expand_tensor.size())

print('\n')

# repeat ì‚¬ìš©í•˜ì—¬ (1,1,3) => (4, 1, 3)
repeat_tensor = tensor_a.repeat(4, 1, 1)
print("Shape of repeated tensor:", repeat_tensor.size())

print('\n')

# í‰ë©´í™”ëœ ë·° ìˆ˜ì • í›„ ì›ë³¸ í…ì„œ í™•ì¸
tensor_a[:] = 0

print("Expanded Tensor")
print(expand_tensor) # ê°’ ë³€ê²½ì´ ë¨

print('\n')

print("Repeated Tensor")
print(repeat_tensor) # ê¹‚ ë³€ê²½ ì•ˆë¨
```

    Original Tensor Size
    torch.Size([1, 1, 3])
    tensor([[[0.8880, 0.6426, 0.6744]]])
    
    
    Shape of expanded tensor: torch.Size([4, 1, 3])
    
    
    Shape of repeated tensor: torch.Size([4, 1, 3])
    
    
    Expanded Tensor
    tensor([[[0., 0., 0.]],
    
            [[0., 0., 0.]],
    
            [[0., 0., 0.]],
    
            [[0., 0., 0.]]])
    
    
    Repeated Tensor
    tensor([[[0.8880, 0.6426, 0.6744]],
    
            [[0.8880, 0.6426, 0.6744]],
    
            [[0.8880, 0.6426, 0.6744]],
    
            [[0.8880, 0.6426, 0.6744]]])
    

## 3. í…ì„œ í•©ì¹˜ê¸° ë‚˜ëˆ„ê¸°


- 3-1. ì—¬ëŸ¬ í…ì„œë¥¼ í•©ì¹˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ
- 3-2. í•˜ë‚˜ì˜ í…ì„œë¥¼ ì—¬ëŸ¬ í…ì„œë¡œ ë‚˜ëˆ„ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ


### 3-1 ì—¬ëŸ¬ í…ì„œë¥¼ í•©ì¹˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ

> ì—¬ëŸ¬ í…ì„œë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ í•©ì³ì„œ ìƒˆë¡œìš´ í…ì„œë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ ì•Œì•„ë´…ë‹ˆë‹¤.



#### ğŸ“ ì„¤ëª… : ì—¬ëŸ¬ í…ì„œ í•©ì¹˜ê¸°
* cat : ì£¼ì–´ì§„ ì°¨ì›ì„ ë”°ë¼ í…ì„œë“¤ì„ ì—°ê²°í•©ë‹ˆë‹¤. (ì£¼ì–´ì§„ ì°¨ì› ì™¸ì˜ ë‹¤ë¥¸ ì°¨ì›ì˜ í¬ê¸°ê°€ ê°™ì•„ì•¼í•©ë‹ˆë‹¤.)

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [cat] : https://pytorch.org/docs/stable/generated/torch.cat.html


```python
tensor_a = torch.randint(1, 10, (2, 3)) # 1ë¶€í„° 9ê¹Œì§€ì˜ ë¬´ì‘ìœ„ ì •ìˆ˜ê°€ ìˆëŠ” (2,3) Tensor
tensor_b = torch.rand(5, 3) # 0ë¶€í„° 1ê¹Œì§€ì˜ ê· ë“±ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” (5,3) Tensor

print("Tensor A shape : ", tensor_a.size())
print(tensor_a)

print('\n')

print("Tensor B shape : ", tensor_b.size())
print(tensor_b)

print('\n')

a_cat_b_row = torch.cat((tensor_a, tensor_b), dim=0) # dim = 0 (í–‰), Tensor A ì™€ Tensor B ë¥¼ í–‰ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹œë‹¤.
print("Concat Tensor A and B (by row) Shape : ", a_cat_b_row.shape) # (Tensor A í–‰ ê°œìˆ˜ + Tensor B í–‰ ê°œìˆ˜, Tensor A/B ì—´ ê°œìˆ˜)
print(a_cat_b_row)
```

    Tensor A shape :  torch.Size([2, 3])
    tensor([[3, 1, 1],
            [9, 6, 7]])
    
    
    Tensor B shape :  torch.Size([5, 3])
    tensor([[0.7098, 0.1477, 0.1453],
            [0.0746, 0.5604, 0.2862],
            [0.4602, 0.4730, 0.4643],
            [0.4764, 0.1533, 0.3704],
            [0.5958, 0.8291, 0.7434]])
    
    
    Concat Tensor A and B (by row) Shape :  torch.Size([7, 3])
    tensor([[3.0000, 1.0000, 1.0000],
            [9.0000, 6.0000, 7.0000],
            [0.7098, 0.1477, 0.1453],
            [0.0746, 0.5604, 0.2862],
            [0.4602, 0.4730, 0.4643],
            [0.4764, 0.1533, 0.3704],
            [0.5958, 0.8291, 0.7434]])
    

#### ğŸ“ ì„¤ëª… : ì—¬ëŸ¬ í…ì„œ í•©ì¹˜ê¸°
* stack : ì£¼ì–´ì§„ ì°¨ì›ì„ ìƒˆë¡œìš´ ì°¨ì›ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ í…ì„œë“¤ì„ ìŒ“ìŠµë‹ˆë‹¤.
  * í•©ì³ì§ˆ í…ì„œë“¤ì˜ í¬ê¸°ëŠ” ëª¨ë‘ ê°™ì•„ì•¼í•©ë‹ˆë‹¤.

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [stack] : https://pytorch.org/docs/stable/generated/torch.stack.html


```python
tensor_a = torch.randint(1, 10, (3, 2))  # 1ë¶€í„° 9ê¹Œì§€ì˜ ë¬´ì‘ìœ„ ì •ìˆ˜ê°€ ìˆëŠ” (3,2) Tensor
tensor_b = torch.rand(3, 2)  # 0ë¶€í„° 1ê¹Œì§€ì˜ ê· ë“±ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” (3,2) Tensor

print("Tensor A shape : ", tensor_a.size())
print(tensor_a)

print('\n')

print("Tensor B shape : ", tensor_b.size())
print(tensor_b)

print('\n')

stack_tensor_row = torch.stack([tensor_a, tensor_b], dim=0)  # dim = 0, í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ Tensor A ì— Tensor B ë¥¼ ìŒ“ê¸°
print("Stack A and B (by row): ", stack_tensor_row.size()) # (ìŒ“ì€ Tensor ê°œìˆ˜, Tensor A/B í–‰ ê°œìˆ˜, Tensor A/B ì—´ ê°œìˆ˜)
print(stack_tensor_row)
```

    Tensor A shape :  torch.Size([3, 2])
    tensor([[9, 9],
            [1, 6],
            [2, 2]])
    
    
    Tensor B shape :  torch.Size([3, 2])
    tensor([[0.5477, 0.6201],
            [0.8358, 0.7233],
            [0.4310, 0.2094]])
    
    
    Stack A and B (by row):  torch.Size([2, 3, 2])
    tensor([[[9.0000, 9.0000],
             [1.0000, 6.0000],
             [2.0000, 2.0000]],
    
            [[0.5477, 0.6201],
             [0.8358, 0.7233],
             [0.4310, 0.2094]]])
    

### 3-2. í•˜ë‚˜ì˜ í…ì„œë¥¼ ì—¬ëŸ¬ í…ì„œë¡œ ë‚˜ëˆ„ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ

> í•˜ë‚˜ì˜ í…ì„œë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ì„ í†µí•´ ì—¬ëŸ¬ í…ì„œë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì„ ì•Œì•„ë´…ë‹ˆë‹¤.

#### ğŸ“ ì„¤ëª… : í…ì„œ ë‚˜ëˆ„ê¸°
* chunk : ë‚˜ëˆ„ê³ ì í•˜ëŠ” **í…ì„œì˜ ê°œìˆ˜**ë¥¼ ì§€ì •í•˜ì—¬ ì›ë˜ì˜ í…ì„œë¥¼ ê°œìˆ˜ì— ë§ê²Œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
  * chunks ì¸ì
    * ëª‡ **ê°œ**ì˜ í…ì„œë¡œ ë‚˜ëˆŒ ê²ƒì¸ì§€

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [chunk] : https://pytorch.org/docs/stable/generated/torch.chunk.html


```python
tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) í…ì„œ
print("Original : ", tensor_a)

print('\n')

chunk_num = 3
chunk_tensor = torch.chunk(tensor_a, chunks = chunk_num, dim=0)  # dim = 0 (í–‰), 6ê°œì˜ í–‰ì´ 3ê°œë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì§€ë¯€ë¡œ 3ê°œì˜ í…ì„œë¡œ ë¶„ë¦¬
print(f'{len(chunk_tensor)} ê°œì˜ Tensorë¡œ ë¶„ë¦¬')

print('\n')

for idx,a in enumerate(chunk_tensor):
    print(f'{idx} ë²ˆì§¸ Tensor \n{a}')
    print(f'{idx} ë²ˆì§¸ Tensor í¬ê¸°', a.size())
    print('---'*10)
```

    Original :  tensor([[9, 2, 4, 5],
            [8, 8, 9, 1],
            [5, 6, 6, 3],
            [7, 8, 3, 2],
            [1, 9, 6, 7],
            [9, 7, 4, 2]])
    
    
    3 ê°œì˜ Tensorë¡œ ë¶„ë¦¬
    
    
    0 ë²ˆì§¸ Tensor 
    tensor([[9, 2, 4, 5],
            [8, 8, 9, 1]])
    0 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([2, 4])
    ------------------------------
    1 ë²ˆì§¸ Tensor 
    tensor([[5, 6, 6, 3],
            [7, 8, 3, 2]])
    1 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([2, 4])
    ------------------------------
    2 ë²ˆì§¸ Tensor 
    tensor([[1, 9, 6, 7],
            [9, 7, 4, 2]])
    2 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([2, 4])
    ------------------------------
    

#### ğŸ“ ì„¤ëª… : í…ì„œ ë‚˜ëˆ„ê¸°
* split : ì…ë ¥í•œ **í¬ê¸°**ë¡œ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ í…ì„œë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
  * split_size_or_sections ì¸ì
    * split_size (int): ì–¼ë§ˆë§Œí¼ì˜ í¬ê¸°ë¡œ ìë¥¼ ê²ƒì¸ì§€
    * sections (list): ì–¼ë§ˆë§Œí¼ì˜ í¬ê¸°ë¡œ **ê°ê°** ìë¥¼ ê²ƒì¸ì§€ (ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ê° í…ì„œì˜ í¬ê¸°ë¥¼ ê°ê° ì§€ì •í•´ ì¤„ ìˆ˜ ìˆìŒ)

ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:
* [split] : https://pytorch.org/docs/stable/generated/torch.split.html


```python
tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) í…ì„œ
print(tensor_a)

print('\n')

split_size = 2
split_tensor = torch.split(tensor_a , split_size_or_sections = split_size, dim=0)  # dim = 0 (í–‰), í…ì„œ A ë¥¼ í–‰ì˜ ê¸¸ì´ê°€ 2 (split_size)ì¸ í…ì„œë¡œ ë‚˜ëˆ”
print(f'{len(split_tensor)} ê°œì˜ Tensorë¡œ ë¶„ë¦¬')

print('\n')

for idx,a in enumerate(split_tensor):
    print(f'{idx} ë²ˆì§¸ Tensor \n{a}')
    print(f'{idx} ë²ˆì§¸ Tensor í¬ê¸°', a.size())
    print('---'*10)
```

    tensor([[3, 3, 3, 4],
            [3, 9, 4, 2],
            [7, 4, 8, 2],
            [4, 8, 9, 8],
            [4, 9, 8, 5],
            [1, 7, 7, 8]])
    
    
    3 ê°œì˜ Tensorë¡œ ë¶„ë¦¬
    
    
    0 ë²ˆì§¸ Tensor 
    tensor([[3, 3, 3, 4],
            [3, 9, 4, 2]])
    0 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([2, 4])
    ------------------------------
    1 ë²ˆì§¸ Tensor 
    tensor([[7, 4, 8, 2],
            [4, 8, 9, 8]])
    1 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([2, 4])
    ------------------------------
    2 ë²ˆì§¸ Tensor 
    tensor([[4, 9, 8, 5],
            [1, 7, 7, 8]])
    2 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([2, 4])
    ------------------------------
    


```python
tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) í…ì„œ
print("Original : ", tensor_a)

print('\n')

split_num = [2, 4]
split_tensor = torch.split(tensor_a, split_size_or_sections = split_num, dim=0)  # dim = 0 (í–‰), í…ì„œ A ë¥¼ í–‰ì˜ ê¸¸ì´ê°€ (2ê°œì¸ í…ì„œì™€ 4ê°œì¸ í…ì„œ)ë¡œ ë‚˜ëˆ”
print(f'{len(split_tensor)} ê°œì˜ Tensorë¡œ ë¶„ë¦¬')

print('\n')

for idx,a in enumerate(split_tensor):
    print(f'{idx} ë²ˆì§¸ Tensor \n{a}')
    print(f'{idx} ë²ˆì§¸ Tensor í¬ê¸°', a.size())
    print('---'*10)
```

    Original :  tensor([[5, 9, 4, 3],
            [8, 4, 4, 6],
            [3, 6, 3, 3],
            [3, 7, 7, 9],
            [2, 8, 8, 8],
            [5, 6, 1, 5]])
    
    
    2 ê°œì˜ Tensorë¡œ ë¶„ë¦¬
    
    
    0 ë²ˆì§¸ Tensor 
    tensor([[5, 9, 4, 3],
            [8, 4, 4, 6]])
    0 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([2, 4])
    ------------------------------
    1 ë²ˆì§¸ Tensor 
    tensor([[3, 6, 3, 3],
            [3, 7, 7, 9],
            [2, 8, 8, 8],
            [5, 6, 1, 5]])
    1 ë²ˆì§¸ Tensor í¬ê¸° torch.Size([4, 4])
    ------------------------------
    

#Reference
> <b><font color = green>(ğŸ“’ê°€ì´ë“œ)
- <a href='https://pytorch.org/docs/stable/index.html'>PyTorch ê³µì‹ ë¬¸ì„œ</a>
- <a href='https://inmoonlight.github.io/2021/03/03/PyTorch-view-transpose-reshape/'>view, transpose, reshape ë¹„êµ</a>

## Required Package

> torch == 2.0.1

## ì½˜í…ì¸  ë¼ì´ì„ ìŠ¤

ì €ì‘ê¶Œ : <font color='blue'> <b> Â©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>

<font color='red'><b>WARNING</font> : ë³¸ êµìœ¡ ì½˜í…ì¸ ì˜ ì§€ì‹ì¬ì‚°ê¶Œì€ ì—…ìŠ¤í…Œì´ì§€ ë° íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì— ê·€ì†ë©ë‹ˆë‹¤. ë³¸ ì½˜í…ì¸ ë¥¼ ì–´ë– í•œ ê²½ë¡œë¡œë“  ì™¸ë¶€ë¡œ ìœ ì¶œ ë° ìˆ˜ì •í•˜ëŠ” í–‰ìœ„ë¥¼ ì—„ê²©íˆ ê¸ˆí•©ë‹ˆë‹¤. </b>


```python

```

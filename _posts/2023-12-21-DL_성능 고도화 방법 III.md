---
layout: post
title: DL 성능 고도화 방법 III
date: 2023-12-21 11:44 +0900
last_modified_at: 2023-12-21 17:50:00 +0900
tags: [DeepLearning]
toc:  true
---

## 데이터 증강 및 그 외 방법들

### 1. 데이터 증강 기법

학습 데이터가 부족하다면, 일반적으로 과적합이 발생한다.

다만 더이상 데이터를 구할 수 없는 상황이라면, 데이터 증강 기법(Data argument)를 고려해 볼 수 있다.

<ins>기본적인 이미지 데이터 증강 기법</ins>

이미지 사이즈 조절 (resize)<br>
회전(rotation)<br>
뒤집기(flipping)<br>
자르기(crop)<br>
<br>
텐서플로우나 파이토치에서 이미 기본적인 데이터 증강 기법을 지원한다.

라이브러리로는 <ins>Albumentations</ins>에서 다양한 이미지 증강을 지원한다.<br>
마찬가지로, <ins>ImgAug</ins>에서 객체 인식과 같은 태스크에서 정답 레이블을 수정해야할 경우 활용한다.

<mark>주의 해야할 점</mark>

해당 데이터의 domain을 잘 고려해서 처리해야한다. 문맥이나 의미를 고려해서 수행해야한다.

ex. 나침반을 학습할 때, 방향정보가 깨지기 때문에 함부로 rotation, flipping을 할 수 없다.<br>
글자를 rotation, flipping을 할 경우, 완전히 다른 글자가 될 수 있다. (6 / 9)

cf ) 그 외 다양한 기법

1. Cutout : 이미지의 일부 영역을 검은색 또는 특정 값으로 가리는 방법

2. Mixup : 두 이미지의 픽셀 값을 선형적으로 조합해서 새로운 이미지 생성

3. CutMix : 하나의 이미지에서 잘라낸 영역을 다른 이미지에 붙여 넣는 방식<br>
두 영역의 정답 레이블이 생길수도 있음

#### 마찬가지로 Text data에도 증강이 가능하다.

1. 동의어 대체<br>
문장에서 불용어가 아닌 동의어를 대체하는 방법
2. 무작위 삽입<br>
동의어, 부사를 무작위로 삽입하는 방법
3. 무작위 교체
4. 무작위 삭제

의미 유지 변환 방법<br>
문장의 의미를 유지하면서 다양한 구조적 변화나 문법적 변화를 주는 방법<br>
의미는 그대로지만 다양한 문장을 만들 수 있다.

역변역<br>
문장을 다른언어로 번역하고, 다시 target 언어로 번역하는 방법

Pretrained LM을 이용하는 방법<br>
BERT, GPT2, BART와 같은 것을 이용하는 방법

### 2. 전이 학습

이미 다른 문제에 대해 학습된 모델의 지식을 새로운 작업에 활용하는 방법<br>
= 하나의 문제를 해결하기 위해 학습된 지식을 다른 문제에 <mark>전이(transfer)</mark>하는 방법이다.

#### 한계

Source 데이터 셋과 Target 데이터 셋의 도메인간의 큰 차이가 나게 되면 전이학습을 하기 어렵다.<br>
또한 많은 레이어를 학습시키기 때문에 과적합의 위험이 있다.

### 3. 자기 지도 학습

전통적인 지도학습은 데이터의 레이블에 크게 의존한다.

그러나 이러한 레이블링은 시간과 비용이 많이 드는 작업이며, 때로는 전문 지식이 필요하다.

자기 지도 학습은 레이블이 명시적으로 제공되지 않아도 스스로 학습할 수 있도록 하는 방식<br>
데이터 내부의 패턴이나 구조를 이용해 '가상의'레이블 또는 문제를 만들고, 이를 통해 모델이 유용한 특징을 추출하도록 학습한다.<br>
ex. 이미지의 일부분을 가리고 가려진 부분 예측 / 이미지를 회전시킨 후 회전각 예측

#### 생성학습(Generative Learning)

대표적인 자기지도학습

동일한 이미지를 다르게 변형하거나 조작해서 '원본 이미지'와 '변형된 이미지'의 관계를 학습하는 방식을 사용<br>
$\RightArrow$ 이미지 자체가 레이블의 역할

#### 대체 작업 학습 (Proxy Task Learning)

대리 작업을 사용해 모델을 학습한다.

분류를 할때, label을 맞추는것 까지 하는게 아니라, 1차적으로 같은 특징을 가지는 데이터를 묶는것을 해보고, 이후에 labeling을 진행

#### 대조 학습 (Contrastive Learning)

상대적인 class를 거리를 통해 나누어 이를 목표로 분류와 같은 task를 하게 된다.

